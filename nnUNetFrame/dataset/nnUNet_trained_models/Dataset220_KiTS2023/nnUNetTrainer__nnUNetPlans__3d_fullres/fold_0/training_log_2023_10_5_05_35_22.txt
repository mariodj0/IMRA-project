
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [417.0, 512.0, 512.0], 'spacing': [1.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset220_KiTS2023', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [104, 512, 512], 'image_reader_writer': 'NibabelIOWithReorient', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 103.13614654541016, 'median': 102.0, 'min': -1021.0, 'percentile_00_5': -58.0, 'percentile_99_5': 302.0, 'std': 73.3431396484375}}} 
 
2023-10-05 05:35:31.196456: unpacking dataset... 
2023-10-05 05:42:00.223455: unpacking done... 
2023-10-05 05:42:00.841909: do_dummy_2d_data_aug: False 
2023-10-05 05:42:00.861394: Using splits from existing split file: /content/drive/MyDrive/nnUNetFrame/dataset/nnUNet_preprocessed/Dataset220_KiTS2023/splits_final.json 
2023-10-05 05:42:01.463189: The split file contains 5 splits. 
2023-10-05 05:42:01.467266: Desired fold for training: 0 
2023-10-05 05:42:01.469908: This split has 120 training and 30 validation cases. 
2023-10-05 05:42:16.807051:  
2023-10-05 05:42:16.809095: Epoch 29 
2023-10-05 05:42:16.813660: Current learning rate: 0.00974 
2023-10-05 05:51:29.077577: train_loss -0.4896 
2023-10-05 05:51:29.722757: val_loss -0.4733 
2023-10-05 05:51:29.728882: Pseudo dice [0.8786, 0.6243, 0.6073] 
2023-10-05 05:51:29.732229: Epoch time: 552.27 s 
2023-10-05 05:51:29.735716: Yayy! New best EMA pseudo Dice: 0.6521 
2023-10-05 05:51:35.032844:  
2023-10-05 05:51:35.035296: Epoch 30 
2023-10-05 05:51:35.037588: Current learning rate: 0.00973 
2023-10-05 05:59:18.703385: train_loss -0.4003 
2023-10-05 05:59:20.314600: val_loss -0.4856 
2023-10-05 05:59:20.324887: Pseudo dice [0.8582, 0.7397, 0.7384] 
2023-10-05 05:59:22.994530: Epoch time: 463.66 s 
2023-10-05 05:59:22.998857: Yayy! New best EMA pseudo Dice: 0.6647 
2023-10-05 05:59:27.401905:  
2023-10-05 05:59:27.404484: Epoch 31 
2023-10-05 05:59:27.409472: Current learning rate: 0.00972 
2023-10-05 06:06:44.719123: train_loss -0.5069 
2023-10-05 06:06:45.335070: val_loss -0.5483 
2023-10-05 06:06:45.344233: Pseudo dice [0.8811, 0.7215, 0.7195] 
2023-10-05 06:06:45.347065: Epoch time: 437.32 s 
2023-10-05 06:06:45.349574: Yayy! New best EMA pseudo Dice: 0.6757 
2023-10-05 06:06:50.992132:  
2023-10-05 06:06:53.361815: Epoch 32 
2023-10-05 06:06:53.367641: Current learning rate: 0.00971 
2023-10-05 06:14:31.148229: train_loss -0.4811 
2023-10-05 06:14:31.774894: val_loss -0.5126 
2023-10-05 06:14:31.789347: Pseudo dice [0.8865, 0.6758, 0.653] 
2023-10-05 06:14:31.793161: Epoch time: 460.15 s 
2023-10-05 06:14:31.797559: Yayy! New best EMA pseudo Dice: 0.6819 
2023-10-05 06:14:42.446776:  
2023-10-05 06:14:42.450041: Epoch 33 
2023-10-05 06:14:42.452707: Current learning rate: 0.0097 
2023-10-05 06:22:14.464786: train_loss -0.5498 
2023-10-05 06:22:15.050056: val_loss -0.5905 
2023-10-05 06:22:15.077312: Pseudo dice [0.9001, 0.7434, 0.7252] 
2023-10-05 06:22:15.086697: Epoch time: 452.01 s 
2023-10-05 06:22:15.095010: Yayy! New best EMA pseudo Dice: 0.6927 
2023-10-05 06:22:23.362644:  
2023-10-05 06:22:23.365189: Epoch 34 
2023-10-05 06:22:23.368854: Current learning rate: 0.00969 
2023-10-05 06:29:26.649835: train_loss -0.5419 
2023-10-05 06:29:27.233242: val_loss -0.4477 
2023-10-05 06:29:27.239580: Pseudo dice [0.8787, 0.6897, 0.6597] 
2023-10-05 06:29:27.247587: Epoch time: 423.29 s 
2023-10-05 06:29:27.256774: Yayy! New best EMA pseudo Dice: 0.6977 
2023-10-05 06:29:35.423306:  
2023-10-05 06:29:35.427087: Epoch 35 
2023-10-05 06:29:35.431792: Current learning rate: 0.00968 
2023-10-05 06:37:10.848313: train_loss -0.51 
2023-10-05 06:37:11.632893: val_loss -0.4911 
2023-10-05 06:37:11.849729: Pseudo dice [0.8794, 0.6881, 0.6642] 
2023-10-05 06:37:12.017934: Epoch time: 455.42 s 
2023-10-05 06:37:12.118543: Yayy! New best EMA pseudo Dice: 0.7023 
2023-10-05 06:37:17.493125:  
2023-10-05 06:37:17.496001: Epoch 36 
2023-10-05 06:37:17.498887: Current learning rate: 0.00968 
2023-10-05 06:45:12.634999: train_loss -0.5214 
2023-10-05 06:45:13.482549: val_loss -0.5257 
2023-10-05 06:45:13.497243: Pseudo dice [0.8869, 0.7571, 0.7365] 
2023-10-05 06:45:13.500450: Epoch time: 475.14 s 
2023-10-05 06:45:13.503804: Yayy! New best EMA pseudo Dice: 0.7114 
2023-10-05 06:45:18.343754:  
2023-10-05 06:45:18.346809: Epoch 37 
2023-10-05 06:45:18.349542: Current learning rate: 0.00967 
2023-10-05 06:52:38.346689: train_loss -0.5618 
2023-10-05 06:52:39.279256: val_loss -0.5616 
2023-10-05 06:52:39.287909: Pseudo dice [0.884, 0.728, 0.7227] 
2023-10-05 06:52:39.296461: Epoch time: 439.98 s 
2023-10-05 06:52:39.300016: Yayy! New best EMA pseudo Dice: 0.7181 
2023-10-05 06:52:46.740760:  
2023-10-05 06:52:46.744311: Epoch 38 
2023-10-05 06:52:46.747282: Current learning rate: 0.00966 
2023-10-05 07:00:15.501760: train_loss -0.5282 
2023-10-05 07:00:17.232896: val_loss -0.406 
2023-10-05 07:00:17.244142: Pseudo dice [0.8113, 0.5192, 0.5103] 
2023-10-05 07:00:17.248120: Epoch time: 448.76 s 
2023-10-05 07:00:19.994160:  
2023-10-05 07:00:20.061994: Epoch 39 
2023-10-05 07:00:20.142167: Current learning rate: 0.00965 
2023-10-05 07:07:52.608180: train_loss -0.547 
2023-10-05 07:07:53.304348: val_loss -0.4842 
2023-10-05 07:07:53.331591: Pseudo dice [0.8199, 0.6577, 0.6508] 
2023-10-05 07:07:53.345183: Epoch time: 452.61 s 
2023-10-05 07:07:56.031532:  
2023-10-05 07:07:56.035482: Epoch 40 
2023-10-05 07:07:56.051042: Current learning rate: 0.00964 
2023-10-05 07:15:01.795152: train_loss -0.5252 
2023-10-05 07:15:02.648413: val_loss -0.5799 
2023-10-05 07:15:02.661609: Pseudo dice [0.9124, 0.8096, 0.7916] 
2023-10-05 07:15:02.671755: Epoch time: 425.76 s 
2023-10-05 07:15:02.675705: Yayy! New best EMA pseudo Dice: 0.7209 
2023-10-05 07:15:09.315860:  
2023-10-05 07:15:09.318424: Epoch 41 
2023-10-05 07:15:09.321064: Current learning rate: 0.00963 
2023-10-05 07:22:21.248575: train_loss -0.522 
2023-10-05 07:22:21.850522: val_loss -0.5405 
2023-10-05 07:22:21.864968: Pseudo dice [0.9027, 0.7162, 0.6776] 
2023-10-05 07:22:21.869666: Epoch time: 431.92 s 
2023-10-05 07:22:21.872078: Yayy! New best EMA pseudo Dice: 0.7253 
2023-10-05 07:22:27.185151:  
2023-10-05 07:22:27.187749: Epoch 42 
2023-10-05 07:22:27.191047: Current learning rate: 0.00962 
2023-10-05 07:30:01.973798: train_loss -0.5591 
2023-10-05 07:30:02.994723: val_loss -0.4823 
2023-10-05 07:30:04.911839: Pseudo dice [0.8462, 0.6624, 0.6458] 
2023-10-05 07:30:04.985643: Epoch time: 454.79 s 
2023-10-05 07:30:08.488103:  
2023-10-05 07:30:08.492375: Epoch 43 
2023-10-05 07:30:08.497140: Current learning rate: 0.00961 
2023-10-05 07:38:18.925315: train_loss -0.6013 
2023-10-05 07:38:19.531979: val_loss -0.6062 
2023-10-05 07:38:19.546270: Pseudo dice [0.9202, 0.7544, 0.7169] 
2023-10-05 07:38:19.550785: Epoch time: 490.43 s 
2023-10-05 07:38:19.555099: Yayy! New best EMA pseudo Dice: 0.7319 
2023-10-05 07:38:26.451522:  
2023-10-05 07:38:26.454460: Epoch 44 
2023-10-05 07:38:26.457345: Current learning rate: 0.0096 
2023-10-05 07:45:57.307729: train_loss -0.573 
2023-10-05 07:46:00.129431: val_loss -0.5862 
2023-10-05 07:46:00.143370: Pseudo dice [0.8967, 0.7571, 0.757] 
2023-10-05 07:46:00.148942: Epoch time: 450.85 s 
2023-10-05 07:46:00.154086: Yayy! New best EMA pseudo Dice: 0.739 
2023-10-05 07:46:05.394046:  
2023-10-05 07:46:05.396772: Epoch 45 
2023-10-05 07:46:05.399619: Current learning rate: 0.00959 
2023-10-05 07:53:39.774645: train_loss -0.4806 
2023-10-05 07:53:40.407304: val_loss -0.5853 
2023-10-05 07:53:40.419832: Pseudo dice [0.8714, 0.7308, 0.7329] 
2023-10-05 07:53:40.423109: Epoch time: 454.38 s 
2023-10-05 07:53:40.426030: Yayy! New best EMA pseudo Dice: 0.743 
2023-10-05 07:53:46.735725:  
2023-10-05 07:53:46.738607: Epoch 46 
2023-10-05 07:53:46.741695: Current learning rate: 0.00959 
2023-10-05 08:00:58.231105: train_loss -0.565 
2023-10-05 08:00:59.879885: val_loss -0.5764 
2023-10-05 08:00:59.895942: Pseudo dice [0.9109, 0.8029, 0.803] 
2023-10-05 08:00:59.900188: Epoch time: 431.49 s 
2023-10-05 08:00:59.904021: Yayy! New best EMA pseudo Dice: 0.7526 
2023-10-05 08:01:07.442924:  
2023-10-05 08:01:07.462244: Epoch 47 
2023-10-05 08:01:07.465177: Current learning rate: 0.00958 
2023-10-05 08:08:29.340900: train_loss -0.5909 
2023-10-05 08:08:30.020534: val_loss -0.5491 
2023-10-05 08:08:30.147776: Pseudo dice [0.8978, 0.6948, 0.6884] 
2023-10-05 08:08:30.265651: Epoch time: 441.9 s 
2023-10-05 08:08:30.307853: Yayy! New best EMA pseudo Dice: 0.7533 
2023-10-05 08:08:37.265155:  
2023-10-05 08:08:37.267478: Epoch 48 
2023-10-05 08:08:37.269991: Current learning rate: 0.00957 
2023-10-05 08:16:02.183989: train_loss -0.5978 
2023-10-05 08:16:02.819867: val_loss -0.464 
2023-10-05 08:16:02.831701: Pseudo dice [0.8462, 0.6155, 0.6017] 
2023-10-05 08:16:02.835046: Epoch time: 444.91 s 
2023-10-05 08:16:09.383322:  
2023-10-05 08:16:09.385897: Epoch 49 
2023-10-05 08:16:09.388449: Current learning rate: 0.00956 
2023-10-05 08:24:07.440097: train_loss -0.5804 
2023-10-05 08:24:08.149514: val_loss -0.4755 
2023-10-05 08:24:08.164825: Pseudo dice [0.8282, 0.6218, 0.6102] 
2023-10-05 08:24:08.167917: Epoch time: 478.05 s 
2023-10-05 08:24:11.572726:  
2023-10-05 08:24:11.579340: Epoch 50 
2023-10-05 08:24:11.581905: Current learning rate: 0.00955 
2023-10-05 08:31:48.622170: train_loss -0.5764 
2023-10-05 08:31:49.264228: val_loss -0.6024 
2023-10-05 08:31:49.269090: Pseudo dice [0.9241, 0.8135, 0.772] 
2023-10-05 08:31:49.272657: Epoch time: 457.04 s 
2023-10-05 08:31:52.119106:  
2023-10-05 08:31:52.122786: Epoch 51 
2023-10-05 08:31:52.125677: Current learning rate: 0.00954 
2023-10-05 08:39:03.103747: train_loss -0.6016 
2023-10-05 08:39:03.776476: val_loss -0.6256 
2023-10-05 08:39:03.791457: Pseudo dice [0.9109, 0.7806, 0.783] 
2023-10-05 08:39:03.794165: Epoch time: 430.99 s 
2023-10-05 08:39:03.796749: Yayy! New best EMA pseudo Dice: 0.7578 
2023-10-05 08:39:10.531626:  
2023-10-05 08:39:10.534171: Epoch 52 
2023-10-05 08:39:11.511574: Current learning rate: 0.00953 
2023-10-05 08:46:27.037289: train_loss -0.5927 
2023-10-05 08:46:27.906269: val_loss -0.5963 
2023-10-05 08:46:27.944545: Pseudo dice [0.8921, 0.7324, 0.7133] 
2023-10-05 08:46:27.954103: Epoch time: 436.48 s 
2023-10-05 08:46:27.958902: Yayy! New best EMA pseudo Dice: 0.7599 
2023-10-05 08:46:33.529605:  
2023-10-05 08:46:33.532311: Epoch 53 
2023-10-05 08:46:33.535086: Current learning rate: 0.00952 
2023-10-05 08:53:57.151635: train_loss -0.5541 
2023-10-05 08:53:57.789565: val_loss -0.5833 
2023-10-05 08:53:57.807436: Pseudo dice [0.8818, 0.7508, 0.7519] 
2023-10-05 08:53:57.873760: Epoch time: 443.61 s 
2023-10-05 08:53:57.944024: Yayy! New best EMA pseudo Dice: 0.7634 
2023-10-05 08:54:03.803388:  
2023-10-05 08:54:03.806131: Epoch 54 
2023-10-05 08:54:03.809059: Current learning rate: 0.00951 
2023-10-05 09:01:52.368289: train_loss -0.5519 
2023-10-05 09:01:53.088711: val_loss -0.5887 
2023-10-05 09:01:53.204890: Pseudo dice [0.8978, 0.7726, 0.7534] 
2023-10-05 09:01:53.227813: Epoch time: 468.57 s 
2023-10-05 09:01:53.238806: Yayy! New best EMA pseudo Dice: 0.7679 
2023-10-05 09:02:00.611691:  
2023-10-05 09:02:00.614493: Epoch 55 
2023-10-05 09:02:00.617307: Current learning rate: 0.0095 
2023-10-05 09:09:25.337402: train_loss -0.6166 
2023-10-05 09:09:25.969778: val_loss -0.7034 
2023-10-05 09:09:25.981392: Pseudo dice [0.9351, 0.8575, 0.8555] 
2023-10-05 09:09:25.984303: Epoch time: 444.72 s 
2023-10-05 09:09:25.987255: Yayy! New best EMA pseudo Dice: 0.7794 
2023-10-05 09:09:32.356991:  
2023-10-05 09:09:32.604664: Epoch 56 
2023-10-05 09:09:32.825874: Current learning rate: 0.00949 
2023-10-05 09:16:57.488225: train_loss -0.6196 
2023-10-05 09:17:00.084364: val_loss -0.5811 
2023-10-05 09:17:00.100446: Pseudo dice [0.9119, 0.7274, 0.7089] 
2023-10-05 09:17:00.109782: Epoch time: 445.13 s 
2023-10-05 09:17:00.116756: Yayy! New best EMA pseudo Dice: 0.7797 
2023-10-05 09:17:08.936696:  
2023-10-05 09:17:08.939238: Epoch 57 
2023-10-05 09:17:08.944132: Current learning rate: 0.00949 
2023-10-05 09:23:58.824843: train_loss -0.5912 
2023-10-05 09:24:01.012336: val_loss -0.5964 
2023-10-05 09:24:01.701153: Pseudo dice [0.8746, 0.7524, 0.7521] 
2023-10-05 09:24:02.226304: Epoch time: 409.88 s 
2023-10-05 09:24:02.311486: Yayy! New best EMA pseudo Dice: 0.781 
2023-10-05 09:24:10.604228:  
2023-10-05 09:24:10.607279: Epoch 58 
2023-10-05 09:24:10.610244: Current learning rate: 0.00948 
2023-10-05 09:31:54.036915: train_loss -0.595 
2023-10-05 09:31:55.551145: val_loss -0.6551 
2023-10-05 09:31:55.571862: Pseudo dice [0.9262, 0.7951, 0.7703] 
2023-10-05 09:31:55.582909: Epoch time: 463.43 s 
2023-10-05 09:31:55.590963: Yayy! New best EMA pseudo Dice: 0.786 
2023-10-05 09:32:01.810414:  
2023-10-05 09:32:01.812984: Epoch 59 
2023-10-05 09:32:01.815603: Current learning rate: 0.00947 
2023-10-05 09:39:50.240348: train_loss -0.5833 
2023-10-05 09:39:51.652248: val_loss -0.6227 
2023-10-05 09:39:51.677161: Pseudo dice [0.9156, 0.7759, 0.7549] 
2023-10-05 09:39:51.693164: Epoch time: 468.42 s 
2023-10-05 09:39:51.702874: Yayy! New best EMA pseudo Dice: 0.7889 
2023-10-05 09:39:58.471838:  
2023-10-05 09:39:58.475416: Epoch 60 
2023-10-05 09:39:58.477993: Current learning rate: 0.00946 
2023-10-05 09:47:39.499896: train_loss -0.6198 
2023-10-05 09:47:40.274057: val_loss -0.6717 
2023-10-05 09:47:40.285669: Pseudo dice [0.9309, 0.8785, 0.8759] 
2023-10-05 09:47:40.288307: Epoch time: 461.02 s 
2023-10-05 09:47:40.293326: Yayy! New best EMA pseudo Dice: 0.7995 
2023-10-05 09:47:46.302930:  
2023-10-05 09:47:46.436429: Epoch 61 
2023-10-05 09:47:46.472340: Current learning rate: 0.00945 
2023-10-05 09:55:21.922848: train_loss -0.5873 
2023-10-05 09:55:22.593594: val_loss -0.6223 
2023-10-05 09:55:22.609486: Pseudo dice [0.9211, 0.7926, 0.7905] 
2023-10-05 09:55:22.614086: Epoch time: 455.62 s 
2023-10-05 09:55:22.618183: Yayy! New best EMA pseudo Dice: 0.8031 
2023-10-05 09:55:28.999759:  
2023-10-05 09:55:29.005135: Epoch 62 
2023-10-05 09:55:29.011247: Current learning rate: 0.00944 
2023-10-05 10:02:59.031903: train_loss -0.622 
2023-10-05 10:03:00.167777: val_loss -0.5756 
2023-10-05 10:03:00.679614: Pseudo dice [0.8901, 0.7633, 0.7479] 
2023-10-05 10:03:00.745134: Epoch time: 450.03 s 
2023-10-05 10:03:03.544990:  
2023-10-05 10:03:04.608901: Epoch 63 
2023-10-05 10:03:04.674401: Current learning rate: 0.00943 
2023-10-05 10:10:33.525942: train_loss -0.5736 
2023-10-05 10:10:39.130575: val_loss -0.612 
2023-10-05 10:10:39.149174: Pseudo dice [0.875, 0.7196, 0.716] 
2023-10-05 10:10:39.151500: Epoch time: 449.98 s 
2023-10-05 10:10:41.518124:  
2023-10-05 10:10:41.521331: Epoch 64 
2023-10-05 10:10:41.524794: Current learning rate: 0.00942 
2023-10-05 10:17:54.559557: train_loss -0.5817 
2023-10-05 10:17:55.372950: val_loss -0.6885 
2023-10-05 10:17:55.512914: Pseudo dice [0.9364, 0.8563, 0.8507] 
2023-10-05 10:17:55.553118: Epoch time: 433.03 s 
2023-10-05 10:17:55.561989: Yayy! New best EMA pseudo Dice: 0.8077 
2023-10-05 10:18:07.584280:  
2023-10-05 10:18:07.587590: Epoch 65 
2023-10-05 10:18:07.592413: Current learning rate: 0.00941 
