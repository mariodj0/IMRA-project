
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [417.0, 512.0, 512.0], 'spacing': [1.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5, 5], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset220_KiTS2023', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [104, 512, 512], 'image_reader_writer': 'NibabelIOWithReorient', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 103.13614654541016, 'median': 102.0, 'min': -1021.0, 'percentile_00_5': -58.0, 'percentile_99_5': 302.0, 'std': 73.3431396484375}}} 
 
2023-10-05 01:09:55.474778: unpacking dataset... 
2023-10-05 01:15:02.417190: unpacking done... 
2023-10-05 01:15:03.125691: do_dummy_2d_data_aug: False 
2023-10-05 01:15:03.146162: Creating new 5-fold cross-validation split... 
2023-10-05 01:15:03.166794: Desired fold for training: 0 
2023-10-05 01:15:03.169067: This split has 120 training and 30 validation cases. 
2023-10-05 01:15:20.216155:  
2023-10-05 01:15:20.217917: Epoch 0 
2023-10-05 01:15:20.220034: Current learning rate: 0.01 
2023-10-05 01:26:09.290381: train_loss 0.0857 
2023-10-05 01:26:09.881994: val_loss 0.0383 
2023-10-05 01:26:09.885797: Pseudo dice [0.4162, 0.0, 0.0] 
2023-10-05 01:26:09.888855: Epoch time: 649.07 s 
2023-10-05 01:26:09.892748: Yayy! New best EMA pseudo Dice: 0.1387 
2023-10-05 01:26:13.152180:  
2023-10-05 01:26:13.154969: Epoch 1 
2023-10-05 01:26:13.156933: Current learning rate: 0.00999 
2023-10-05 01:34:13.788020: train_loss -0.0505 
2023-10-05 01:34:14.400183: val_loss -0.0163 
2023-10-05 01:34:14.416805: Pseudo dice [0.4906, 0.0, 0.0] 
2023-10-05 01:34:14.447037: Epoch time: 480.63 s 
2023-10-05 01:34:14.457248: Yayy! New best EMA pseudo Dice: 0.1412 
2023-10-05 01:34:20.455145:  
2023-10-05 01:34:20.457747: Epoch 2 
2023-10-05 01:34:20.464840: Current learning rate: 0.00998 
2023-10-05 01:41:49.988528: train_loss -0.0794 
2023-10-05 01:41:50.862873: val_loss -0.1306 
2023-10-05 01:41:50.872784: Pseudo dice [0.6317, 0.1554, 0.1523] 
2023-10-05 01:41:50.879046: Epoch time: 449.53 s 
2023-10-05 01:41:50.885423: Yayy! New best EMA pseudo Dice: 0.1584 
2023-10-05 01:41:58.059224:  
2023-10-05 01:41:58.061589: Epoch 3 
2023-10-05 01:41:58.063881: Current learning rate: 0.00997 
2023-10-05 01:49:52.160288: train_loss -0.1353 
2023-10-05 01:49:52.786626: val_loss -0.1738 
2023-10-05 01:49:52.817109: Pseudo dice [0.6306, 0.3597, 0.3453] 
2023-10-05 01:49:52.825891: Epoch time: 474.1 s 
2023-10-05 01:49:52.840941: Yayy! New best EMA pseudo Dice: 0.1871 
2023-10-05 01:49:58.885508:  
2023-10-05 01:49:58.887965: Epoch 4 
2023-10-05 01:49:58.890332: Current learning rate: 0.00996 
2023-10-05 01:57:21.592248: train_loss -0.1516 
2023-10-05 01:57:22.200154: val_loss -0.1294 
2023-10-05 01:57:23.732345: Pseudo dice [0.6163, 0.1985, 0.179] 
2023-10-05 01:57:23.740210: Epoch time: 442.7 s 
2023-10-05 01:57:23.744218: Yayy! New best EMA pseudo Dice: 0.2015 
2023-10-05 01:57:29.249063:  
2023-10-05 01:57:29.251726: Epoch 5 
2023-10-05 01:57:29.254762: Current learning rate: 0.00995 
2023-10-05 02:04:53.848866: train_loss -0.1933 
2023-10-05 02:04:54.452687: val_loss -0.1995 
2023-10-05 02:04:54.460483: Pseudo dice [0.6631, 0.4139, 0.4006] 
2023-10-05 02:04:54.463040: Epoch time: 444.6 s 
2023-10-05 02:04:54.465141: Yayy! New best EMA pseudo Dice: 0.2306 
2023-10-05 02:05:01.349854:  
2023-10-05 02:05:01.352367: Epoch 6 
2023-10-05 02:05:01.354933: Current learning rate: 0.00995 
2023-10-05 02:12:04.936015: train_loss -0.1754 
2023-10-05 02:12:05.950631: val_loss -0.2323 
2023-10-05 02:12:05.962696: Pseudo dice [0.6717, 0.4639, 0.447] 
2023-10-05 02:12:05.970225: Epoch time: 423.58 s 
2023-10-05 02:12:05.978111: Yayy! New best EMA pseudo Dice: 0.2603 
2023-10-05 02:12:13.895434:  
2023-10-05 02:12:13.898159: Epoch 7 
2023-10-05 02:12:13.901879: Current learning rate: 0.00994 
2023-10-05 02:19:30.094382: train_loss -0.2176 
2023-10-05 02:19:31.878793: val_loss -0.2437 
2023-10-05 02:19:31.897328: Pseudo dice [0.6756, 0.4201, 0.396] 
2023-10-05 02:19:31.909765: Epoch time: 436.2 s 
2023-10-05 02:19:31.923504: Yayy! New best EMA pseudo Dice: 0.284 
2023-10-05 02:19:39.932173:  
2023-10-05 02:19:39.935758: Epoch 8 
2023-10-05 02:19:39.939256: Current learning rate: 0.00993 
2023-10-05 02:26:50.110620: train_loss -0.2611 
2023-10-05 02:26:50.793807: val_loss -0.213 
2023-10-05 02:26:50.841046: Pseudo dice [0.6732, 0.4479, 0.435] 
2023-10-05 02:26:50.851529: Epoch time: 430.15 s 
2023-10-05 02:26:50.862242: Yayy! New best EMA pseudo Dice: 0.3075 
2023-10-05 02:26:56.431669:  
2023-10-05 02:26:56.434587: Epoch 9 
2023-10-05 02:26:56.438374: Current learning rate: 0.00992 
2023-10-05 02:34:39.848374: train_loss -0.2429 
2023-10-05 02:34:40.435279: val_loss -0.245 
2023-10-05 02:34:40.445810: Pseudo dice [0.7007, 0.4162, 0.4108] 
2023-10-05 02:34:40.448797: Epoch time: 463.41 s 
2023-10-05 02:34:40.452280: Yayy! New best EMA pseudo Dice: 0.3276 
2023-10-05 02:34:45.835236:  
2023-10-05 02:34:45.838071: Epoch 10 
2023-10-05 02:34:45.840922: Current learning rate: 0.00991 
2023-10-05 02:41:55.814242: train_loss -0.3283 
2023-10-05 02:41:57.481889: val_loss -0.2034 
2023-10-05 02:41:57.492559: Pseudo dice [0.6835, 0.3201, 0.3237] 
2023-10-05 02:41:57.497485: Epoch time: 429.98 s 
2023-10-05 02:41:57.503148: Yayy! New best EMA pseudo Dice: 0.3391 
2023-10-05 02:42:02.598935:  
2023-10-05 02:42:02.603970: Epoch 11 
2023-10-05 02:42:02.609723: Current learning rate: 0.0099 
2023-10-05 02:49:49.716329: train_loss -0.3106 
2023-10-05 02:49:50.314379: val_loss -0.2916 
2023-10-05 02:49:51.032240: Pseudo dice [0.7205, 0.5125, 0.506] 
2023-10-05 02:49:51.045341: Epoch time: 467.11 s 
2023-10-05 02:49:51.051712: Yayy! New best EMA pseudo Dice: 0.3632 
2023-10-05 02:49:56.336645:  
2023-10-05 02:49:56.339524: Epoch 12 
2023-10-05 02:49:56.342704: Current learning rate: 0.00989 
2023-10-05 02:57:10.387490: train_loss -0.3491 
2023-10-05 02:57:10.992728: val_loss -0.3678 
2023-10-05 02:57:11.000983: Pseudo dice [0.8181, 0.5815, 0.5526] 
2023-10-05 02:57:11.007083: Epoch time: 434.04 s 
2023-10-05 02:57:11.011282: Yayy! New best EMA pseudo Dice: 0.3919 
2023-10-05 02:57:16.133873:  
2023-10-05 02:57:16.136479: Epoch 13 
2023-10-05 02:57:16.149615: Current learning rate: 0.00988 
2023-10-05 03:04:38.942546: train_loss -0.3189 
2023-10-05 03:04:39.620770: val_loss -0.3388 
2023-10-05 03:04:39.627256: Pseudo dice [0.8091, 0.5218, 0.4925] 
2023-10-05 03:04:39.634829: Epoch time: 442.8 s 
2023-10-05 03:04:39.641360: Yayy! New best EMA pseudo Dice: 0.4135 
2023-10-05 03:04:52.029175:  
2023-10-05 03:04:52.032543: Epoch 14 
2023-10-05 03:04:52.035304: Current learning rate: 0.00987 
2023-10-05 03:12:13.649423: train_loss -0.4058 
2023-10-05 03:12:14.290119: val_loss -0.342 
2023-10-05 03:12:14.321943: Pseudo dice [0.7873, 0.4395, 0.4238] 
2023-10-05 03:12:14.328933: Epoch time: 441.62 s 
2023-10-05 03:12:14.338416: Yayy! New best EMA pseudo Dice: 0.4272 
2023-10-05 03:12:24.259640:  
2023-10-05 03:12:24.262565: Epoch 15 
2023-10-05 03:12:24.264508: Current learning rate: 0.00986 
2023-10-05 03:20:10.440851: train_loss -0.3951 
2023-10-05 03:20:11.693188: val_loss -0.4658 
2023-10-05 03:20:11.702329: Pseudo dice [0.8362, 0.6331, 0.6331] 
2023-10-05 03:20:11.705485: Epoch time: 466.18 s 
2023-10-05 03:20:11.708187: Yayy! New best EMA pseudo Dice: 0.4546 
2023-10-05 03:20:18.042274:  
2023-10-05 03:20:18.045005: Epoch 16 
2023-10-05 03:20:18.047579: Current learning rate: 0.00986 
2023-10-05 03:27:29.560564: train_loss -0.414 
2023-10-05 03:27:30.402844: val_loss -0.4163 
2023-10-05 03:27:30.504156: Pseudo dice [0.8393, 0.6401, 0.6311] 
2023-10-05 03:27:30.586359: Epoch time: 431.52 s 
2023-10-05 03:27:30.719162: Yayy! New best EMA pseudo Dice: 0.4794 
2023-10-05 03:27:36.273797:  
2023-10-05 03:27:39.012243: Epoch 17 
2023-10-05 03:27:39.016643: Current learning rate: 0.00985 
2023-10-05 03:34:42.569805: train_loss -0.3854 
2023-10-05 03:34:43.212689: val_loss -0.3687 
2023-10-05 03:34:43.226090: Pseudo dice [0.8382, 0.6456, 0.638] 
2023-10-05 03:34:43.235706: Epoch time: 426.29 s 
2023-10-05 03:34:43.244388: Yayy! New best EMA pseudo Dice: 0.5022 
2023-10-05 03:34:49.515306:  
2023-10-05 03:34:49.517742: Epoch 18 
2023-10-05 03:34:49.520251: Current learning rate: 0.00984 
2023-10-05 03:42:22.097951: train_loss -0.3863 
2023-10-05 03:42:24.687330: val_loss -0.444 
2023-10-05 03:42:24.821417: Pseudo dice [0.8483, 0.6365, 0.6193] 
2023-10-05 03:42:24.831852: Epoch time: 452.57 s 
2023-10-05 03:42:28.552407: Yayy! New best EMA pseudo Dice: 0.5221 
2023-10-05 03:42:34.649865:  
2023-10-05 03:42:34.652234: Epoch 19 
2023-10-05 03:42:34.654405: Current learning rate: 0.00983 
2023-10-05 03:49:40.910361: train_loss -0.4264 
2023-10-05 03:49:41.544114: val_loss -0.3986 
2023-10-05 03:49:41.561159: Pseudo dice [0.7991, 0.6276, 0.6283] 
2023-10-05 03:49:41.573329: Epoch time: 426.25 s 
2023-10-05 03:49:41.582836: Yayy! New best EMA pseudo Dice: 0.5384 
2023-10-05 03:49:49.176640:  
2023-10-05 03:49:49.179868: Epoch 20 
2023-10-05 03:49:49.182775: Current learning rate: 0.00982 
2023-10-05 03:57:23.273250: train_loss -0.4387 
2023-10-05 03:57:23.881700: val_loss -0.4887 
2023-10-05 03:57:23.895509: Pseudo dice [0.8365, 0.691, 0.6783] 
2023-10-05 03:57:23.900115: Epoch time: 454.09 s 
2023-10-05 03:57:23.904533: Yayy! New best EMA pseudo Dice: 0.5581 
2023-10-05 03:57:29.713786:  
2023-10-05 03:57:29.716840: Epoch 21 
2023-10-05 03:57:29.719693: Current learning rate: 0.00981 
2023-10-05 04:04:56.466824: train_loss -0.4673 
2023-10-05 04:04:57.080660: val_loss -0.4947 
2023-10-05 04:04:57.090969: Pseudo dice [0.8521, 0.7073, 0.6892] 
2023-10-05 04:04:57.094827: Epoch time: 446.75 s 
2023-10-05 04:04:57.098956: Yayy! New best EMA pseudo Dice: 0.5772 
2023-10-05 04:05:01.809516:  
2023-10-05 04:05:01.812156: Epoch 22 
2023-10-05 04:05:01.813728: Current learning rate: 0.0098 
2023-10-05 04:12:27.002880: train_loss -0.4714 
2023-10-05 04:12:27.585696: val_loss -0.297 
2023-10-05 04:12:27.592083: Pseudo dice [0.7883, 0.3787, 0.3553] 
2023-10-05 04:12:27.596707: Epoch time: 445.19 s 
2023-10-05 04:12:30.058683:  
2023-10-05 04:12:30.061357: Epoch 23 
2023-10-05 04:12:30.064629: Current learning rate: 0.00979 
2023-10-05 04:19:38.856929: train_loss -0.4126 
2023-10-05 04:19:39.467067: val_loss -0.313 
2023-10-05 04:19:39.688592: Pseudo dice [0.7829, 0.4684, 0.4592] 
2023-10-05 04:19:39.933361: Epoch time: 428.8 s 
2023-10-05 04:19:42.712589:  
2023-10-05 04:19:42.721873: Epoch 24 
2023-10-05 04:19:42.731023: Current learning rate: 0.00978 
2023-10-05 04:26:50.652786: train_loss -0.4806 
2023-10-05 04:26:52.256941: val_loss -0.4837 
2023-10-05 04:26:52.274047: Pseudo dice [0.8492, 0.6909, 0.6873] 
2023-10-05 04:26:52.279462: Epoch time: 427.93 s 
2023-10-05 04:26:52.285062: Yayy! New best EMA pseudo Dice: 0.5875 
2023-10-05 04:26:58.688517:  
2023-10-05 04:26:58.691846: Epoch 25 
2023-10-05 04:26:58.695343: Current learning rate: 0.00977 
2023-10-05 04:34:27.550379: train_loss -0.467 
2023-10-05 04:34:29.175289: val_loss -0.4466 
2023-10-05 04:34:29.183769: Pseudo dice [0.8212, 0.5997, 0.5958] 
2023-10-05 04:34:29.188353: Epoch time: 448.86 s 
2023-10-05 04:34:29.193032: Yayy! New best EMA pseudo Dice: 0.5959 
2023-10-05 04:34:34.511632:  
2023-10-05 04:34:34.514507: Epoch 26 
2023-10-05 04:34:34.517443: Current learning rate: 0.00977 
2023-10-05 04:42:13.746578: train_loss -0.4938 
2023-10-05 04:42:14.716028: val_loss -0.5095 
2023-10-05 04:42:14.734381: Pseudo dice [0.877, 0.7301, 0.7289] 
2023-10-05 04:42:14.742188: Epoch time: 459.23 s 
2023-10-05 04:42:14.747482: Yayy! New best EMA pseudo Dice: 0.6142 
2023-10-05 04:42:21.749301:  
2023-10-05 04:42:21.754457: Epoch 27 
2023-10-05 04:42:22.839681: Current learning rate: 0.00976 
2023-10-05 04:49:47.062673: train_loss -0.4881 
2023-10-05 04:49:47.664227: val_loss -0.531 
2023-10-05 04:49:47.668877: Pseudo dice [0.8975, 0.7479, 0.73] 
2023-10-05 04:49:47.677035: Epoch time: 445.31 s 
2023-10-05 04:49:47.681441: Yayy! New best EMA pseudo Dice: 0.632 
2023-10-05 04:49:54.264295:  
2023-10-05 04:49:54.269570: Epoch 28 
2023-10-05 04:49:54.277149: Current learning rate: 0.00975 
2023-10-05 04:57:14.178248: train_loss -0.4809 
2023-10-05 04:57:14.795596: val_loss -0.523 
2023-10-05 04:57:14.809300: Pseudo dice [0.8794, 0.7381, 0.7101] 
2023-10-05 04:57:14.813258: Epoch time: 439.91 s 
2023-10-05 04:57:14.820292: Yayy! New best EMA pseudo Dice: 0.6464 
2023-10-05 04:57:19.915781:  
2023-10-05 04:57:19.933850: Epoch 29 
2023-10-05 04:57:19.936515: Current learning rate: 0.00974 
